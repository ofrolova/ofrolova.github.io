<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Gen AI Highlights of 2024: A Year in Review | Olga Frolova</title>
<meta name="keywords" content="">
<meta name="description" content="As 2024 wraps up, I wanted to share a quick rundown of the major generative AI developments that stood out this year. This post is based on a presentation I gave back in December, drawing from research and hands-on experience applying these tools to projects (especially at the prototype stage) in the video game industry.
Let’s dive in.
GPT-4o: Smarter, Clearer, More Capable
The biggest leap came from OpenAI with the release of GPT-4o. What makes this model stand out isn’t just its speed but how well it reasons. It walks you through its logic step by step, which makes it especially useful for complex math, debugging code, or explaining difficult concepts.">
<meta name="author" content="">
<link rel="canonical" href="https://ofrolova.github.io/posts/gen_ai_highlights/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://ofrolova.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ofrolova.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ofrolova.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ofrolova.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://ofrolova.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://ofrolova.github.io/posts/gen_ai_highlights/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://ofrolova.github.io/posts/gen_ai_highlights/">
  <meta property="og:site_name" content="Olga Frolova">
  <meta property="og:title" content="Gen AI Highlights of 2024: A Year in Review">
  <meta property="og:description" content="As 2024 wraps up, I wanted to share a quick rundown of the major generative AI developments that stood out this year. This post is based on a presentation I gave back in December, drawing from research and hands-on experience applying these tools to projects (especially at the prototype stage) in the video game industry.
Let’s dive in.
GPT-4o: Smarter, Clearer, More Capable The biggest leap came from OpenAI with the release of GPT-4o. What makes this model stand out isn’t just its speed but how well it reasons. It walks you through its logic step by step, which makes it especially useful for complex math, debugging code, or explaining difficult concepts.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-12-12T09:43:40-04:00">
    <meta property="article:modified_time" content="2024-12-12T09:43:40-04:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Gen AI Highlights of 2024: A Year in Review">
<meta name="twitter:description" content="As 2024 wraps up, I wanted to share a quick rundown of the major generative AI developments that stood out this year. This post is based on a presentation I gave back in December, drawing from research and hands-on experience applying these tools to projects (especially at the prototype stage) in the video game industry.
Let’s dive in.
GPT-4o: Smarter, Clearer, More Capable
The biggest leap came from OpenAI with the release of GPT-4o. What makes this model stand out isn’t just its speed but how well it reasons. It walks you through its logic step by step, which makes it especially useful for complex math, debugging code, or explaining difficult concepts.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://ofrolova.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Gen AI Highlights of 2024: A Year in Review",
      "item": "https://ofrolova.github.io/posts/gen_ai_highlights/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Gen AI Highlights of 2024: A Year in Review",
  "name": "Gen AI Highlights of 2024: A Year in Review",
  "description": "As 2024 wraps up, I wanted to share a quick rundown of the major generative AI developments that stood out this year. This post is based on a presentation I gave back in December, drawing from research and hands-on experience applying these tools to projects (especially at the prototype stage) in the video game industry.\nLet’s dive in.\nGPT-4o: Smarter, Clearer, More Capable The biggest leap came from OpenAI with the release of GPT-4o. What makes this model stand out isn’t just its speed but how well it reasons. It walks you through its logic step by step, which makes it especially useful for complex math, debugging code, or explaining difficult concepts.\n",
  "keywords": [
    
  ],
  "articleBody": "As 2024 wraps up, I wanted to share a quick rundown of the major generative AI developments that stood out this year. This post is based on a presentation I gave back in December, drawing from research and hands-on experience applying these tools to projects (especially at the prototype stage) in the video game industry.\nLet’s dive in.\nGPT-4o: Smarter, Clearer, More Capable The biggest leap came from OpenAI with the release of GPT-4o. What makes this model stand out isn’t just its speed but how well it reasons. It walks you through its logic step by step, which makes it especially useful for complex math, debugging code, or explaining difficult concepts.\nWhat’s even more interesting is where the next wave of OpenAI models is heading. In evaluation tests, their reasoning-focused model has started to perform on par with PhD-level researchers in subjects like physics, chemistry, and biology. The jump in math and coding ability has been even more striking: in one qualifying exam for the International Mathematics Olympiad, GPT-4o managed to solve about 13% of problems, while the reasoning model got to 83%. In competitive programming trials on Codeforces, it ranked around the 89th percentile.\nAlongside this, OpenAI also launched o1-mini — a smaller reasoning model designed to be both faster and more affordable. It’s tuned heavily toward coding tasks, coming in at about 80% cheaper to run than o1-preview. For teams that need reasoning without the overhead of full world knowledge, o1-mini is shaping up to be a cost-effective option.\nAnother big shift was the introduction of OpenAI Canvas, a new interface designed for writing and coding directly with ChatGPT. It’s a sign OpenAI is moving toward more specialized workflows. Personally, I still lean on Cursor.ai, especially with Anthropic’s Claude code interpreter integrated. It offers a better coding experience overall, but Canvas is a step in the right direction.\nThey also rolled out voice and image recognition, pushing toward a truly multimodal AI assistant. Voice input is smoother than before (though still best in English), and image interpretation has gotten smarter (though not flawless yet).\nImage Generation: Flux AI and Recraft Flux AI Flux AI stayed ahead of the curve in 2024, delivering consistently high-quality image generation and flexible integration via API. What sets it apart:\nTrained on licensed/public domain datasets Works well with Adobe tools Can be fine-tuned on domain-specific datasets But as long as we talk about image generation nothing works better than demonstration. To showcase its latest model, I used this prompt:\n“A majestic castle perched on a rugged, mist-shrouded mountain, surrounded by an ancient forest glowing softly under a twilight sky. The castle’s soaring towers and intricate spires are adorned with elven carvings and shimmering banners. A cascading waterfall flows beside the castle, feeding a crystal-clear river winding through the forest below. In the foreground, a stone bridge crosses the river, leading to the grand, vine-covered gates of the castle. The scene is illuminated by the soft golden glow of lanterns, with distant snow-capped peaks and a crescent moon adding to the Tolkien-inspired fantasy ambiance.”\nThe result? Visually stunning. The model nailed atmospheric lighting, architecture, and fantasy detail with an impressive degree of coherence. That said, like all current models, it still stumbles on finer anatomical features like hands. For production art, human touch remains essential — but this is a major leap forward for concepting and iteration.\nRecraft AI V3 Recraft took everybody by surprise. You don’t see a small startup at the top of artificialanalysis.ai’s leaderboard every day.\nThe model ended up dominating design-centric tasks. It’s the only image model in 2024 that generates vector-native (SVG) images, which means crisp, infinitely scalable assets straight out of the box.\nStandout features include:\nLong-form, accurate text rendering (think logos, headlines, slogans) Built-in tools for background removal, mockups, upscaling, and style merging If your work involves visual branding or web assets, Recraft is hard to beat.\nI also tested Recraft using the same fantasy castle prompt I had tried with Flux AI to push the limits of the model. The results were close: Flux AI produced more intricate architectural details, while Recraft leaned toward a more realistic overall look but dropped a few finer elements. Both were impressive in different ways. Check the slides below for more examples.\nDuring the model testing stage I ran a second prompt describing an elf character to test models’ abilities with humanoid type characters. I happened to write the prompt in a gender-neutral way since I was much more interested if the model can produce a correct position of hands rather than whether it be a male or female elf. I used it across DALL·E, Flux AI, and Recraft. Both DALL·E and Flux defaulted to a female elf, while Recraft generated a male one. Maybe it is a coincidence. But given that only Recraft’s founder is female, I couldn’t help but find it both funny and thought-provoking. Either way, it’s another reminder of how datasets, design choices, and maybe even culture subtly shape these tools.\nVideo RunwayML Runway grew into a true multimedia platform. Beyond its well-known video generation tools, it now includes:\nText-to-speech: Perfect for prototypes and cosept art presentation. Camera angle and motion control: Instead of static, one-shot clips, you can define pans, zooms, and dynamic angles to create more cinematic sequences. Facial mimicry transfer: Upload reference footage of an actor, and Runway can map subtle facial expressions onto generated characters. I haven’t used this one myself but worth mentioning. All of these can be combined in a single workflow. The platform is not replacing traditional 3D or video editing suites yet, but it’s getting close enough that for early iterations, it’s often faster and cheaper to go “AI-first” and polish later.\nMotion Brush by Kling AI This tool lets you animate static images with lifelike movement — ideal for breathing life into concept art. It’s intuitive, fast, and surprisingly accurate for stylized content.\nHeyGen’s Unlimited Looks HeyGen allows you to create a realistic video avatar using just a few minutes of footage. For marketers and content creators, this makes producing personalized, scalable video content much faster and more cost-effective.\nAudio Suno AI Suno nailed the niche of AI-powered music generation. It lets you create custom soundtracks in specific genres and moods without relying on stock libraries. For prototyping games or interactive experiences, this creates a tighter and more immersive feel from the start.\nGoogle Illuminate This lesser-known but highly promising tool turns written content into engaging audio conversations. It’s designed to simplify complex topics and make learning or onboarding more interactive. Think of it as a podcast generator for your documentation or product guides.\nElevenLabs ElevenLabs keeps pushing voice synthesis forward. The realism and language support are so good now that we’ve been using it to generate multilingual placeholder dialogue for early builds. It’s definitely good enough for testing — sometimes good enough to keep.\nDeveloper Tools: Coding Workflows Two tools have become essential parts of our stack:\nCursor.ai Cursor is like having a senior developer on call 24/7. It goes beyond autocomplete: Cursor understands your entire codebase, makes meaningful suggestions, catches bugs, and helps implement new features. The Claude integration adds depth to its reasoning and makes it the best AI dev environment I’ve used so far.\nGitHub Copilot Copilot keeps getting smarter. It’s great for generating boilerplate, writing unit tests, or jumping into unfamiliar code. Its integration into mainstream IDEs means it’s always right there when you need it. Between these two tools, we’ve seen major gains in both speed and quality.\nWrapping Up 2024 wasn’t just about better models, it was about better workflows. The most exciting developments weren’t just smarter tools, but tools that slot seamlessly into how we already work.\nIf you’re experimenting with generative AI or planning to adopt it more fully, now’s the time. The tech has matured to the point where it can genuinely accelerate creative and technical work — not just impress in demos.\nSlides from the Presentation You can view the full slide deck here:\nOpen the slides on Google Drive\n",
  "wordCount" : "1345",
  "inLanguage": "en",
  "datePublished": "2024-12-12T09:43:40-04:00",
  "dateModified": "2024-12-12T09:43:40-04:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ofrolova.github.io/posts/gen_ai_highlights/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Olga Frolova",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ofrolova.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ofrolova.github.io/" accesskey="h" title="Olga Frolova (Alt + H)">Olga Frolova</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://ofrolova.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://ofrolova.github.io/work_with_me" title="Work with me">
                    <span>Work with me</span>
                </a>
            </li>
            <li>
                <a href="https://ofrolova.github.io/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://ofrolova.github.io/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Gen AI Highlights of 2024: A Year in Review
    </h1>
    <div class="post-meta"><span title='2024-12-12 09:43:40 -0400 -0400'>December 12, 2024</span>

</div>
  </header> 
  <div class="post-content"><p>As 2024 wraps up, I wanted to share a quick rundown of the major generative AI developments that stood out this year. This post is based on a presentation I gave back in December, drawing from research and hands-on experience applying these tools to projects (especially at the prototype stage) in the video game industry.</p>
<p>Let’s dive in.</p>
<h2 id="gpt-4o-smarter-clearer-more-capable">GPT-4o: Smarter, Clearer, More Capable<a hidden class="anchor" aria-hidden="true" href="#gpt-4o-smarter-clearer-more-capable">#</a></h2>
<p>The biggest leap came from <a href="https://openai.com">OpenAI</a> with the release of GPT-4o. What makes this model stand out isn’t just its speed but how well it reasons. It walks you through its logic step by step, which makes it especially useful for complex math, debugging code, or explaining difficult concepts.</p>
<p>What’s even more interesting is where the next wave of OpenAI models is heading. In evaluation tests, their reasoning-focused model has started to perform on par with PhD-level researchers in subjects like physics, chemistry, and biology. The jump in math and coding ability has been even more striking: in one qualifying exam for the International Mathematics Olympiad, GPT-4o managed to solve about 13% of problems, while the reasoning model got to 83%. In competitive programming trials on <a href="https://codeforces.com">Codeforces</a>, it ranked around the 89th percentile.</p>
<p>Alongside this, OpenAI also launched o1-mini — a smaller reasoning model designed to be both faster and more affordable. It’s tuned heavily toward coding tasks, coming in at about 80% cheaper to run than o1-preview. For teams that need reasoning without the overhead of full world knowledge, o1-mini is shaping up to be a cost-effective option.</p>
<p>Another big shift was the introduction of OpenAI Canvas, a new interface designed for writing and coding directly with ChatGPT. It’s a sign OpenAI is moving toward more specialized workflows. Personally, I still lean on <a href="https://cursor.sh">Cursor.ai</a>, especially with <a href="https://www.anthropic.com/claude">Anthropic’s Claude</a> code interpreter integrated. It offers a better coding experience overall, but Canvas is a step in the right direction.</p>
<p><img alt="Alt text for accessibility" loading="lazy" src="/images/code_4o.png" title="Optional hover title"></p>
<p>They also rolled out voice and image recognition, pushing toward a truly multimodal AI assistant. Voice input is smoother than before (though still best in English), and image interpretation has gotten smarter (though not flawless yet).</p>
<h2 id="image-generation-flux-ai-and-recraft">Image Generation: Flux AI and Recraft<a hidden class="anchor" aria-hidden="true" href="#image-generation-flux-ai-and-recraft">#</a></h2>
<h3 id="flux-ai"><a href="https://bfl.ai/">Flux AI</a><a hidden class="anchor" aria-hidden="true" href="#flux-ai">#</a></h3>
<p>Flux AI stayed ahead of the curve in 2024, delivering consistently high-quality image generation and flexible integration via API. What sets it apart:</p>
<ul>
<li>Trained on licensed/public domain datasets</li>
<li>Works well with <a href="https://www.adobe.com">Adobe</a> tools</li>
<li>Can be fine-tuned on domain-specific datasets</li>
</ul>
<p>But as long as we talk about image generation nothing works better than demonstration. To showcase its latest model, I used this prompt:</p>
<blockquote>
<p><em>&ldquo;A majestic castle perched on a rugged, mist-shrouded mountain, surrounded by an ancient forest glowing softly under a twilight sky. The castle&rsquo;s soaring towers and intricate spires are adorned with elven carvings and shimmering banners. A cascading waterfall flows beside the castle, feeding a crystal-clear river winding through the forest below. In the foreground, a stone bridge crosses the river, leading to the grand, vine-covered gates of the castle. The scene is illuminated by the soft golden glow of lanterns, with distant snow-capped peaks and a crescent moon adding to the Tolkien-inspired fantasy ambiance.&rdquo;</em></p></blockquote>
<p><img alt="Alt text for accessibility" loading="lazy" src="/images/castle.png" title="Optional hover title"></p>
<p>The result? Visually stunning. The model nailed atmospheric lighting, architecture, and fantasy detail with an impressive degree of coherence. That said, like all current models, it still stumbles on finer anatomical features like hands. For production art, human touch remains essential — but this is a major leap forward for concepting and iteration.</p>
<h3 id="recraft-ai-v3"><a href="https://www.recraft.ai">Recraft AI</a> V3<a hidden class="anchor" aria-hidden="true" href="#recraft-ai-v3">#</a></h3>
<p>Recraft took everybody by surprise. You don’t see a small startup at the top of <a href="https://artificialanalysis.ai">artificialanalysis.ai</a>’s leaderboard every day.</p>
<p><img alt="Alt text for accessibility" loading="lazy" src="/images/recraftai.png" title="Optional hover title"></p>
<p>The model ended up dominating design-centric tasks. It’s the only image model in 2024 that generates vector-native (SVG) images, which means crisp, infinitely scalable assets straight out of the box.</p>
<p>Standout features include:</p>
<ul>
<li>Long-form, accurate text rendering (think logos, headlines, slogans)</li>
<li>Built-in tools for background removal, mockups, upscaling, and style merging</li>
</ul>
<p>If your work involves visual branding or web assets, Recraft is hard to beat.</p>
<p>I also tested Recraft using the same fantasy castle prompt I had tried with Flux AI to push the limits of the model. The results were close: Flux AI produced more intricate architectural details, while Recraft leaned toward a more realistic overall look but dropped a few finer elements. Both were impressive in different ways. Check the <a href="#slides-from-the-presentation">slides below</a> for more examples.</p>
<p><img alt="Alt text for accessibility" loading="lazy" src="/images/castle_recraft.png" title="Optional hover title"></p>
<p>During the model testing stage I ran a second prompt describing an elf character to test models’ abilities with humanoid type characters. I happened to write the prompt in a gender-neutral way since I was much more interested if the model can produce a correct position of hands rather than whether it be a male or female elf. I used it across <a href="https://openai.com/dall-e">DALL·E</a>, Flux AI, and Recraft. Both DALL·E and Flux defaulted to a female elf, while Recraft generated a male one. Maybe it is a coincidence. But given that only Recraft’s founder is female, I couldn’t help but find it both funny and thought-provoking. Either way, it’s another reminder of how datasets, design choices, and maybe even culture subtly shape these tools.</p>
<h2 id="video">Video<a hidden class="anchor" aria-hidden="true" href="#video">#</a></h2>
<h3 id="runwayml"><a href="https://runwayml.com">RunwayML</a><a hidden class="anchor" aria-hidden="true" href="#runwayml">#</a></h3>
<p>Runway grew into a true multimedia platform. Beyond its well-known video generation tools, it now includes:</p>
<ul>
<li>Text-to-speech: Perfect for prototypes and cosept art presentation.</li>
<li>Camera angle and motion control: Instead of static, one-shot clips, you can define pans, zooms, and dynamic angles to create more cinematic sequences.</li>
<li>Facial mimicry transfer: Upload reference footage of an actor, and Runway can map subtle facial expressions onto generated characters. I haven&rsquo;t used this one myself but worth mentioning.</li>
</ul>
<p>All of these can be combined in a single workflow. The platform is not replacing traditional 3D or video editing suites yet, but it’s getting close enough that for early iterations, it’s often faster and cheaper to go “AI-first” and polish later.</p>
<iframe width="560" height="315" 
src="https://www.youtube.com/embed/VRBOMOG2IZY?start=112" 
title="YouTube video player" frameborder="0" 
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
allowfullscreen>
</iframe>
<h3 id="motion-brush-by-kling-ai">Motion Brush by <a href="https://app.klingai.com/">Kling AI</a><a hidden class="anchor" aria-hidden="true" href="#motion-brush-by-kling-ai">#</a></h3>
<p>This tool lets you animate static images with lifelike movement — ideal for breathing life into concept art. It’s intuitive, fast, and surprisingly accurate for stylized content.</p>
<h3 id="heygens-unlimited-looks"><a href="https://www.heygen.com">HeyGen</a>’s Unlimited Looks<a hidden class="anchor" aria-hidden="true" href="#heygens-unlimited-looks">#</a></h3>
<p>HeyGen allows you to create a realistic video avatar using just a few minutes of footage. For marketers and content creators, this makes producing personalized, scalable video content much faster and more cost-effective.</p>
<h2 id="audio">Audio<a hidden class="anchor" aria-hidden="true" href="#audio">#</a></h2>
<h3 id="suno-ai"><a href="https://www.suno.ai">Suno AI</a><a hidden class="anchor" aria-hidden="true" href="#suno-ai">#</a></h3>
<p>Suno nailed the niche of AI-powered music generation. It lets you create custom soundtracks in specific genres and moods without relying on stock libraries. For prototyping games or interactive experiences, this creates a tighter and more immersive feel from the start.</p>
<h3 id="google-illuminate"><a href="https://illuminate.google.com/explore?pli=1">Google</a> Illuminate<a hidden class="anchor" aria-hidden="true" href="#google-illuminate">#</a></h3>
<p>This lesser-known but highly promising tool turns written content into engaging audio conversations. It’s designed to simplify complex topics and make learning or onboarding more interactive. Think of it as a podcast generator for your documentation or product guides.</p>
<h3 id="elevenlabs"><a href="https://elevenlabs.io">ElevenLabs</a><a hidden class="anchor" aria-hidden="true" href="#elevenlabs">#</a></h3>
<p>ElevenLabs keeps pushing voice synthesis forward. The realism and language support are so good now that we’ve been using it to generate multilingual placeholder dialogue for early builds. It’s definitely good enough for testing — sometimes good enough to keep.</p>
<h2 id="developer-tools-coding-workflows">Developer Tools: Coding Workflows<a hidden class="anchor" aria-hidden="true" href="#developer-tools-coding-workflows">#</a></h2>
<p>Two tools have become essential parts of our stack:</p>
<h3 id="cursorai"><a href="https://cursor.sh">Cursor.ai</a><a hidden class="anchor" aria-hidden="true" href="#cursorai">#</a></h3>
<p>Cursor is like having a senior developer on call 24/7. It goes beyond autocomplete: Cursor understands your entire codebase, makes meaningful suggestions, catches bugs, and helps implement new features. The Claude integration adds depth to its reasoning and makes it the best AI dev environment I’ve used so far.</p>
<h3 id="github-copilot"><a href="https://github.com/features/copilot">GitHub Copilot</a><a hidden class="anchor" aria-hidden="true" href="#github-copilot">#</a></h3>
<p>Copilot keeps getting smarter. It’s great for generating boilerplate, writing unit tests, or jumping into unfamiliar code. Its integration into mainstream IDEs means it’s always right there when you need it. Between these two tools, we’ve seen major gains in both speed and quality.</p>
<h2 id="wrapping-up">Wrapping Up<a hidden class="anchor" aria-hidden="true" href="#wrapping-up">#</a></h2>
<p>2024 wasn’t just about better models, it was about better workflows. The most exciting developments weren’t just smarter tools, but tools that slot seamlessly into how we already work.</p>
<p>If you’re experimenting with generative AI or planning to adopt it more fully, now’s the time. The tech has matured to the point where it can genuinely accelerate creative and technical work — not just impress in demos.</p>
<hr>
<h2 id="slides-from-the-presentation">Slides from the Presentation<a hidden class="anchor" aria-hidden="true" href="#slides-from-the-presentation">#</a></h2>
<p>You can view the full slide deck here:<br>
<a href="https://docs.google.com/presentation/d/1n9pot616svMK5U0GrL93E6_eYThGCG9b7S4zZthiXPY/present">Open the slides on Google Drive</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2026 <a href="https://ofrolova.github.io/">Olga Frolova</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
